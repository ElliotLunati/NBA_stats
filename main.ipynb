{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a320e944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_nba_bdd import export_all_seasons, export_all_teams_seasons, export_all_salaries, scrape_mvp_data, merge_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d7426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_all_seasons()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362cf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_all_teams_seasons() # 5min environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d8acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_all_salaries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d4a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_mvp_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb82f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_data() # Pour créer le data set sur lequel appliquer nos modèles (que pour Regular Season pour l'instant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e508aead",
   "metadata": {},
   "source": [
    "# Modèle de prédiction des salaires\n",
    "Entraînement d'un modèle Random Forest pour prédire les salaires ajustés à l'inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10682d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Charger la base de données fusionnée\n",
    "df = pd.read_csv('./data/merged_data.csv')\n",
    "\n",
    "print(f\"Dataset chargé: {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "print(f\"\\nAperçu des colonnes:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef78b424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les premières lignes\n",
    "print(\"\\n Aperçu des données:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\n Informations sur les données:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd1f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Catégoriser la colonne Position avant de la supprimer\n",
    "if 'Position' in df.columns:\n",
    "    print(f\"\\n Positions uniques trouvées:\")\n",
    "    print(df['Position'].value_counts())\n",
    "    \n",
    "    # Créer un mapping des positions vers des catégories numériques\n",
    "    position_mapping = {\n",
    "        'PG': 1,   # Point Guard\n",
    "        'SG': 2,   # Shooting Guard\n",
    "        'SF': 3,   # Small Forward\n",
    "        'PF': 4,   # Power Forward\n",
    "        'C': 5,    # Center\n",
    "        'G': 6,    # Guard (générique)\n",
    "        'F': 7,    # Forward (générique)\n",
    "        'GF': 8,  # Guard-Forward\n",
    "        '': 9     # Position inconnue\n",
    "    }\n",
    "    \n",
    "    # Appliquer le mapping aux positions des joueurs\n",
    "    df['position_category'] = df['Position'].map(position_mapping).fillna(0).astype(int)\n",
    "    print(f\"\\n Colonne 'position_category' créée:\")\n",
    "    print(\"\\n Colonne 'Position' non trouvée dans le dataset\")\n",
    "\n",
    "# Supprimer les colonnes inutiles pour la prédiction\n",
    "columns_to_drop = ['PLAYER_ID', 'PLAYER_NAME', 'NICKNAME', 'TEAM_ABBREVIATION', 'Team', 'Salary', 'Season', 'Position', 'Rank']\n",
    "\n",
    "# Vérifier quelles colonnes existent réellement\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in df.columns]\n",
    "print(f\"\\n Colonnes à supprimer: {existing_columns_to_drop}\")\n",
    "\n",
    "df_clean = df.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "print(f\"\\n Dataset après nettoyage: {len(df_clean)} lignes, {len(df_clean.columns)} colonnes\")\n",
    "print(f\"Colonnes restantes: {df_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e552b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer une colonne catégorielle pour les saisons à partir de 'Year'\n",
    "# Extraire l'année de début (ex: '1999-00' -> 1999)\n",
    "df_clean['season_start_year'] = df_clean['Year'].str.split('-').str[0].astype(int)\n",
    "\n",
    "# Créer une colonne catégorielle (1 pour 1999-00, 2 pour 2000-01, etc.)\n",
    "min_year = df_clean['season_start_year'].min()\n",
    "df_clean['season_category'] = df_clean['season_start_year'] - min_year + 1\n",
    "\n",
    "print(f\"\\n Catégories de saisons créées:\")\n",
    "print(f\"   Année minimale: {min_year} (catégorie 1)\")\n",
    "print(f\"   Année maximale: {df_clean['season_start_year'].max()} (catégorie {df_clean['season_category'].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2986a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les colonnes temporaires et Year\n",
    "df_clean = df_clean.drop(columns=['Year', 'season_start_year'])\n",
    "\n",
    "# Gérer les valeurs manquantes\n",
    "print(f\"\\n Valeurs manquantes par colonne:\")\n",
    "missing_values = df_clean.isnull().sum()\n",
    "print(missing_values[missing_values > 0])\n",
    "\n",
    "# Remplir les valeurs manquantes avec 0 (ou la médiane selon la colonne)\n",
    "df_clean = df_clean.fillna(0)\n",
    "\n",
    "print(f\"\\n Dataset final prêt pour l'entraînement: {len(df_clean)} lignes, {len(df_clean.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43661ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les features (X) et la cible (y)\n",
    "X = df_clean.drop(columns=['adjusted_salary'])\n",
    "y = df_clean['adjusted_salary']\n",
    "\n",
    "print(f\" Variable cible: adjusted_salary\")\n",
    "print(f\" Features: {len(X.columns)} colonnes\")\n",
    "print(f\"   Nombre d'exemples: {len(X)}\")\n",
    "print(f\"\\n Statistiques de la variable cible:\")\n",
    "print(f\"   Moyenne: ${y.mean():,.0f}\")\n",
    "print(f\"   Médiane: ${y.median():,.0f}\")\n",
    "print(f\"   Min: ${y.min():,.0f}\")\n",
    "print(f\"   Max: ${y.max():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diviser les données en ensembles d'entraînement et de test (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\" Division des données:\")\n",
    "print(f\"   Entraînement: {len(X_train)} exemples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   Test: {len(X_test)} exemples ({len(X_test)/len(X)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d791380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer et entraîner le modèle Random Forest\n",
    "print(\"Entraînement du modèle Random Forest...\")\n",
    "print(\"   (Cela peut prendre quelques minutes...)\\n\")\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=100,      # Nombre d'arbres\n",
    "    max_depth=20,          # Profondeur maximale des arbres\n",
    "    min_samples_split=5,   # Nombre minimum d'échantillons pour diviser un nœud\n",
    "    min_samples_leaf=2,    # Nombre minimum d'échantillons par feuille\n",
    "    random_state=42,       # Pour la reproductibilité\n",
    "    n_jobs=-1,             # Utiliser tous les cœurs CPU\n",
    "    verbose=1              # Afficher la progression\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n Modèle entraîné avec succès!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9139ac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faire des prédictions\n",
    "y_train_pred = rf_model.predict(X_train)\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculer les métriques de performance\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\" RÉSULTATS DU MODÈLE RANDOM FOREST\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n Ensemble d'entraînement:\")\n",
    "print(f\"   MAE (Mean Absolute Error):  ${train_mae:,.0f}\")\n",
    "print(f\"   RMSE (Root Mean Squared Error): ${train_rmse:,.0f}\")\n",
    "print(f\"   R² Score: {train_r2:.4f}\")\n",
    "\n",
    "print(\"\\n Ensemble de test:\")\n",
    "print(f\"   MAE (Mean Absolute Error):  ${test_mae:,.0f}\")\n",
    "print(f\"   RMSE (Root Mean Squared Error): ${test_rmse:,.0f}\")\n",
    "print(f\"   R² Score: {test_r2:.4f}\")\n",
    "\n",
    "print(\"\\n Interprétation:\")\n",
    "print(f\"   Le modèle se trompe en moyenne de ${test_mae:,.0f}\")\n",
    "print(f\"   Il explique {test_r2*100:.1f}% de la variance des salaires\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29588074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance des features\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\n TOP 5 des variables les plus importantes:\")\n",
    "print(feature_importance.head(5).to_string(index=False))\n",
    "\n",
    "# Visualiser les 5 features les plus importantes\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_5 = feature_importance.head(5)\n",
    "plt.barh(top_5['feature'], top_5['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 5 des variables les plus importantes pour prédire le salaire')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7a9f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser les prédictions vs valeurs réelles\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Graphique 1: Scatter plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Salaire réel ($)')\n",
    "plt.ylabel('Salaire prédit ($)')\n",
    "plt.title('Prédictions vs Valeurs réelles (Test)')\n",
    "plt.ticklabel_format(style='plain', axis='both')\n",
    "\n",
    "# Graphique 2: Distribution des erreurs\n",
    "plt.subplot(1, 2, 2)\n",
    "errors = y_test - y_test_pred\n",
    "plt.hist(errors, bins=50, edgecolor='black')\n",
    "plt.xlabel('Erreur de prédiction ($)')\n",
    "plt.ylabel('Fréquence')\n",
    "plt.title('Distribution des erreurs de prédiction')\n",
    "plt.axvline(x=0, color='r', linestyle='--', linewidth=2)\n",
    "plt.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Statistiques des erreurs:\")\n",
    "print(f\"   Erreur moyenne: ${errors.mean():,.0f}\")\n",
    "print(f\"   Écart-type des erreurs: ${errors.std():,.0f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
